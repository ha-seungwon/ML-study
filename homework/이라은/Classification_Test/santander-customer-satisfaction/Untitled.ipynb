{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c6fe564-a6a4-428f-a19e-dbcd14d7fae4",
   "metadata": {},
   "source": [
    "# Classification Test\n",
    "# 분류 실습 - 캐글 산탄데르 고객 만족 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed9fc0aa-0f1e-4732-89d6-6a17cef95911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape: (76020, 371)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                 0.0                      0.0   \n",
       "1   3     2     34                 0.0                      0.0   \n",
       "2   4     2     23                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "0                      0.0                      0.0  ...   \n",
       "1                      0.0                      0.0  ...   \n",
       "2                      0.0                      0.0  ...   \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3     var38  TARGET  \n",
       "0                     0.0                     0.0  39205.17       0  \n",
       "1                     0.0                     0.0  49278.03       0  \n",
       "2                     0.0                     0.0  67333.77       0  \n",
       "\n",
       "[3 rows x 371 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 전처리\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import warnings \n",
    "\n",
    "cust_df = pd.read_csv(\"./Classification_Test/santander-customer-satisfaction/train.csv\",encoding='latin-1')\n",
    "print('dataset shape:', cust_df.shape)\n",
    "cust_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b452ffbd-4e75-416d-800e-caff91d302a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76020 entries, 0 to 76019\n",
      "Columns: 371 entries, ID to TARGET\n",
      "dtypes: float64(111), int64(260)\n",
      "memory usage: 215.2 MB\n"
     ]
    }
   ],
   "source": [
    "cust_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1e3366b-4483-43eb-8ebe-ac567e6ebda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    73012\n",
      "1     3008\n",
      "Name: TARGET, dtype: int64\n",
      "unsatisfied 비율은 0.04\n"
     ]
    }
   ],
   "source": [
    "print(cust_df['TARGET'].value_counts())\n",
    "unsatisfied_cnt = cust_df[cust_df['TARGET'] == 1].TARGET.count()\n",
    "total_cnt = cust_df.TARGET.count()\n",
    "print('unsatisfied 비율은 {0:.2f}'.format((unsatisfied_cnt / total_cnt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0e0358e-8a6d-47d0-a320-9d6e76c151eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75964.050723</td>\n",
       "      <td>-1523.199277</td>\n",
       "      <td>33.212865</td>\n",
       "      <td>86.208265</td>\n",
       "      <td>72.363067</td>\n",
       "      <td>119.529632</td>\n",
       "      <td>3.559130</td>\n",
       "      <td>6.472698</td>\n",
       "      <td>0.412946</td>\n",
       "      <td>0.567352</td>\n",
       "      <td>...</td>\n",
       "      <td>7.935824</td>\n",
       "      <td>1.365146</td>\n",
       "      <td>12.215580</td>\n",
       "      <td>8.784074</td>\n",
       "      <td>31.505324</td>\n",
       "      <td>1.858575</td>\n",
       "      <td>76.026165</td>\n",
       "      <td>56.614351</td>\n",
       "      <td>1.172358e+05</td>\n",
       "      <td>0.039569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43781.947379</td>\n",
       "      <td>39033.462364</td>\n",
       "      <td>12.956486</td>\n",
       "      <td>1614.757313</td>\n",
       "      <td>339.315831</td>\n",
       "      <td>546.266294</td>\n",
       "      <td>93.155749</td>\n",
       "      <td>153.737066</td>\n",
       "      <td>30.604864</td>\n",
       "      <td>36.513513</td>\n",
       "      <td>...</td>\n",
       "      <td>455.887218</td>\n",
       "      <td>113.959637</td>\n",
       "      <td>783.207399</td>\n",
       "      <td>538.439211</td>\n",
       "      <td>2013.125393</td>\n",
       "      <td>147.786584</td>\n",
       "      <td>4040.337842</td>\n",
       "      <td>2852.579397</td>\n",
       "      <td>1.826646e+05</td>\n",
       "      <td>0.194945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163750e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38104.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.787061e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76043.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.064092e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>113748.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187563e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151838.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>210000.000000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>21024.810000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>11073.570000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50003.880000</td>\n",
       "      <td>20385.720000</td>\n",
       "      <td>138831.630000</td>\n",
       "      <td>91778.730000</td>\n",
       "      <td>438329.220000</td>\n",
       "      <td>24650.010000</td>\n",
       "      <td>681462.900000</td>\n",
       "      <td>397884.300000</td>\n",
       "      <td>2.203474e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID           var3         var15  imp_ent_var16_ult1  \\\n",
       "count   76020.000000   76020.000000  76020.000000        76020.000000   \n",
       "mean    75964.050723   -1523.199277     33.212865           86.208265   \n",
       "std     43781.947379   39033.462364     12.956486         1614.757313   \n",
       "min         1.000000 -999999.000000      5.000000            0.000000   \n",
       "25%     38104.750000       2.000000     23.000000            0.000000   \n",
       "50%     76043.000000       2.000000     28.000000            0.000000   \n",
       "75%    113748.750000       2.000000     40.000000            0.000000   \n",
       "max    151838.000000     238.000000    105.000000       210000.000000   \n",
       "\n",
       "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 72.363067               119.529632   \n",
       "std                 339.315831               546.266294   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               12888.030000             21024.810000   \n",
       "\n",
       "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  3.559130                 6.472698   \n",
       "std                  93.155749               153.737066   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                8237.820000             11073.570000   \n",
       "\n",
       "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "count             76020.000000             76020.000000  ...   \n",
       "mean                  0.412946                 0.567352  ...   \n",
       "std                  30.604864                36.513513  ...   \n",
       "min                   0.000000                 0.000000  ...   \n",
       "25%                   0.000000                 0.000000  ...   \n",
       "50%                   0.000000                 0.000000  ...   \n",
       "75%                   0.000000                 0.000000  ...   \n",
       "max                6600.000000              6600.000000  ...   \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  7.935824                 1.365146   \n",
       "std                 455.887218               113.959637   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               50003.880000             20385.720000   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "count            76020.000000            76020.000000   \n",
       "mean                12.215580                8.784074   \n",
       "std                783.207399              538.439211   \n",
       "min                  0.000000                0.000000   \n",
       "25%                  0.000000                0.000000   \n",
       "50%                  0.000000                0.000000   \n",
       "75%                  0.000000                0.000000   \n",
       "max             138831.630000            91778.730000   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 31.505324                 1.858575   \n",
       "std                2013.125393               147.786584   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max              438329.220000             24650.010000   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3         var38  \\\n",
       "count            76020.000000            76020.000000  7.602000e+04   \n",
       "mean                76.026165               56.614351  1.172358e+05   \n",
       "std               4040.337842             2852.579397  1.826646e+05   \n",
       "min                  0.000000                0.000000  5.163750e+03   \n",
       "25%                  0.000000                0.000000  6.787061e+04   \n",
       "50%                  0.000000                0.000000  1.064092e+05   \n",
       "75%                  0.000000                0.000000  1.187563e+05   \n",
       "max             681462.900000           397884.300000  2.203474e+07   \n",
       "\n",
       "             TARGET  \n",
       "count  76020.000000  \n",
       "mean       0.039569  \n",
       "std        0.194945  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 371 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.describe( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "020aabdf-b4c6-45b3-a658-f7d3adeba8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "피처 데이터 shape:(76020, 369)\n"
     ]
    }
   ],
   "source": [
    "# var3 피처 값 대체 및 ID 피처 드롭\n",
    "cust_df['var3'].replace(-999999,2, inplace=True)\n",
    "cust_df.drop('ID',axis=1 , inplace=True)\n",
    "\n",
    "# 피처 세트와 레이블 세트분리. 레이블 컬럼은 DataFrame의 맨 마지막에 위치해 컬럼 위치 -1로 분리\n",
    "X_features = cust_df.iloc[:, :-1]\n",
    "y_labels = cust_df.iloc[:, -1]\n",
    "print('피처 데이터 shape:{0}'.format(X_features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e36b44f0-e305-4686-ae9d-0fb422fe8f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 세트 Shape:(60816, 369), 테스트 세트 Shape:(15204, 369)\n",
      " 학습 세트 레이블 값 분포 비율\n",
      "0    0.960964\n",
      "1    0.039036\n",
      "Name: TARGET, dtype: float64\n",
      "\n",
      " 테스트 세트 레이블 값 분포 비율\n",
      "0    0.9583\n",
      "1    0.0417\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_labels,\n",
    "                                                    test_size=0.2, random_state=0)\n",
    "train_cnt = y_train.count()\n",
    "test_cnt = y_test.count()\n",
    "print('학습 세트 Shape:{0}, 테스트 세트 Shape:{1}'.format(X_train.shape , X_test.shape))\n",
    "\n",
    "print(' 학습 세트 레이블 값 분포 비율')\n",
    "print(y_train.value_counts()/train_cnt)\n",
    "print('\\n 테스트 세트 레이블 값 분포 비율')\n",
    "print(y_test.value_counts()/test_cnt)\n",
    "\n",
    "#x_train, y_train을 다시 학습과 검증 데이터 세트로 분리\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size = 0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54b5a96-a0a6-4f9f-89c4-02bc27fa83a8",
   "metadata": {},
   "source": [
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# n_estimators는 500으로, random state는 예제 수행 시마다 동일 예측 결과를 위해 설정. \n",
    "xgb_clf = XGBClassifier(n_estimators=500, learning_rate= 0.05, random_state=156)\n",
    "\n",
    "# 성능 평가 지표를 auc로, 조기 중단 파라미터는 100으로 설정하고 학습 수행. \n",
    "xgb_clf.fit(X_train, y_train, early_stopping_rounds=100,\n",
    "            eval_metric=\"auc\", eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
    "\n",
    "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:,1])\n",
    "print('ROC AUC: {0:.4f}'.format(xgb_roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8959b490-42a0-4f3e-b2b4-a9647287d4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.828636\ttraining's binary_logloss: 0.155736\tvalid_1's auc: 0.808196\tvalid_1's binary_logloss: 0.156452\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.841239\ttraining's binary_logloss: 0.149808\tvalid_1's auc: 0.815261\tvalid_1's binary_logloss: 0.151835\n",
      "[3]\ttraining's auc: 0.84483\ttraining's binary_logloss: 0.145623\tvalid_1's auc: 0.816935\tvalid_1's binary_logloss: 0.148691\n",
      "[4]\ttraining's auc: 0.850625\ttraining's binary_logloss: 0.142238\tvalid_1's auc: 0.817472\tvalid_1's binary_logloss: 0.146268\n",
      "[5]\ttraining's auc: 0.855207\ttraining's binary_logloss: 0.139453\tvalid_1's auc: 0.818418\tvalid_1's binary_logloss: 0.144276\n",
      "[6]\ttraining's auc: 0.857737\ttraining's binary_logloss: 0.137218\tvalid_1's auc: 0.819067\tvalid_1's binary_logloss: 0.142647\n",
      "[7]\ttraining's auc: 0.859875\ttraining's binary_logloss: 0.135124\tvalid_1's auc: 0.819713\tvalid_1's binary_logloss: 0.141414\n",
      "[8]\ttraining's auc: 0.863294\ttraining's binary_logloss: 0.133312\tvalid_1's auc: 0.819605\tvalid_1's binary_logloss: 0.140408\n",
      "[9]\ttraining's auc: 0.86458\ttraining's binary_logloss: 0.131743\tvalid_1's auc: 0.81964\tvalid_1's binary_logloss: 0.139586\n",
      "[10]\ttraining's auc: 0.866287\ttraining's binary_logloss: 0.130397\tvalid_1's auc: 0.820894\tvalid_1's binary_logloss: 0.138759\n",
      "[11]\ttraining's auc: 0.869815\ttraining's binary_logloss: 0.129182\tvalid_1's auc: 0.822503\tvalid_1's binary_logloss: 0.138138\n",
      "[12]\ttraining's auc: 0.871812\ttraining's binary_logloss: 0.127956\tvalid_1's auc: 0.82362\tvalid_1's binary_logloss: 0.137493\n",
      "[13]\ttraining's auc: 0.87487\ttraining's binary_logloss: 0.126964\tvalid_1's auc: 0.823787\tvalid_1's binary_logloss: 0.137099\n",
      "[14]\ttraining's auc: 0.877683\ttraining's binary_logloss: 0.125843\tvalid_1's auc: 0.824109\tvalid_1's binary_logloss: 0.136649\n",
      "[15]\ttraining's auc: 0.878575\ttraining's binary_logloss: 0.124998\tvalid_1's auc: 0.825554\tvalid_1's binary_logloss: 0.136265\n",
      "[16]\ttraining's auc: 0.879758\ttraining's binary_logloss: 0.124206\tvalid_1's auc: 0.826261\tvalid_1's binary_logloss: 0.136003\n",
      "[17]\ttraining's auc: 0.881562\ttraining's binary_logloss: 0.123444\tvalid_1's auc: 0.826514\tvalid_1's binary_logloss: 0.13579\n",
      "[18]\ttraining's auc: 0.885127\ttraining's binary_logloss: 0.12267\tvalid_1's auc: 0.82675\tvalid_1's binary_logloss: 0.135611\n",
      "[19]\ttraining's auc: 0.886495\ttraining's binary_logloss: 0.121996\tvalid_1's auc: 0.826384\tvalid_1's binary_logloss: 0.135502\n",
      "[20]\ttraining's auc: 0.888084\ttraining's binary_logloss: 0.121321\tvalid_1's auc: 0.826448\tvalid_1's binary_logloss: 0.135388\n",
      "[21]\ttraining's auc: 0.889097\ttraining's binary_logloss: 0.120725\tvalid_1's auc: 0.826549\tvalid_1's binary_logloss: 0.135236\n",
      "[22]\ttraining's auc: 0.891328\ttraining's binary_logloss: 0.119957\tvalid_1's auc: 0.826818\tvalid_1's binary_logloss: 0.135039\n",
      "[23]\ttraining's auc: 0.894144\ttraining's binary_logloss: 0.119212\tvalid_1's auc: 0.826235\tvalid_1's binary_logloss: 0.13503\n",
      "[24]\ttraining's auc: 0.895029\ttraining's binary_logloss: 0.118724\tvalid_1's auc: 0.826381\tvalid_1's binary_logloss: 0.134948\n",
      "[25]\ttraining's auc: 0.897791\ttraining's binary_logloss: 0.117992\tvalid_1's auc: 0.826712\tvalid_1's binary_logloss: 0.134893\n",
      "[26]\ttraining's auc: 0.898706\ttraining's binary_logloss: 0.117468\tvalid_1's auc: 0.82652\tvalid_1's binary_logloss: 0.134922\n",
      "[27]\ttraining's auc: 0.900552\ttraining's binary_logloss: 0.116895\tvalid_1's auc: 0.826416\tvalid_1's binary_logloss: 0.134907\n",
      "[28]\ttraining's auc: 0.901399\ttraining's binary_logloss: 0.116377\tvalid_1's auc: 0.826431\tvalid_1's binary_logloss: 0.134895\n",
      "[29]\ttraining's auc: 0.90229\ttraining's binary_logloss: 0.11587\tvalid_1's auc: 0.826355\tvalid_1's binary_logloss: 0.134874\n",
      "[30]\ttraining's auc: 0.903536\ttraining's binary_logloss: 0.115428\tvalid_1's auc: 0.826531\tvalid_1's binary_logloss: 0.134852\n",
      "[31]\ttraining's auc: 0.905109\ttraining's binary_logloss: 0.114971\tvalid_1's auc: 0.826565\tvalid_1's binary_logloss: 0.13482\n",
      "[32]\ttraining's auc: 0.906528\ttraining's binary_logloss: 0.114474\tvalid_1's auc: 0.826155\tvalid_1's binary_logloss: 0.134859\n",
      "[33]\ttraining's auc: 0.907611\ttraining's binary_logloss: 0.114123\tvalid_1's auc: 0.826425\tvalid_1's binary_logloss: 0.134834\n",
      "[34]\ttraining's auc: 0.90919\ttraining's binary_logloss: 0.113697\tvalid_1's auc: 0.826099\tvalid_1's binary_logloss: 0.134881\n",
      "[35]\ttraining's auc: 0.910018\ttraining's binary_logloss: 0.113297\tvalid_1's auc: 0.826105\tvalid_1's binary_logloss: 0.134893\n",
      "[36]\ttraining's auc: 0.910801\ttraining's binary_logloss: 0.112933\tvalid_1's auc: 0.826286\tvalid_1's binary_logloss: 0.134885\n",
      "[37]\ttraining's auc: 0.911905\ttraining's binary_logloss: 0.112531\tvalid_1's auc: 0.826465\tvalid_1's binary_logloss: 0.134866\n",
      "[38]\ttraining's auc: 0.912667\ttraining's binary_logloss: 0.112126\tvalid_1's auc: 0.826471\tvalid_1's binary_logloss: 0.134913\n",
      "[39]\ttraining's auc: 0.913713\ttraining's binary_logloss: 0.111693\tvalid_1's auc: 0.826506\tvalid_1's binary_logloss: 0.134935\n",
      "[40]\ttraining's auc: 0.914389\ttraining's binary_logloss: 0.111368\tvalid_1's auc: 0.826619\tvalid_1's binary_logloss: 0.13492\n",
      "[41]\ttraining's auc: 0.915363\ttraining's binary_logloss: 0.110996\tvalid_1's auc: 0.826433\tvalid_1's binary_logloss: 0.134974\n",
      "[42]\ttraining's auc: 0.915842\ttraining's binary_logloss: 0.110649\tvalid_1's auc: 0.826451\tvalid_1's binary_logloss: 0.134977\n",
      "[43]\ttraining's auc: 0.916615\ttraining's binary_logloss: 0.110316\tvalid_1's auc: 0.826386\tvalid_1's binary_logloss: 0.135021\n",
      "[44]\ttraining's auc: 0.917117\ttraining's binary_logloss: 0.109998\tvalid_1's auc: 0.82641\tvalid_1's binary_logloss: 0.135057\n",
      "[45]\ttraining's auc: 0.917848\ttraining's binary_logloss: 0.109605\tvalid_1's auc: 0.826543\tvalid_1's binary_logloss: 0.135068\n",
      "[46]\ttraining's auc: 0.918609\ttraining's binary_logloss: 0.109266\tvalid_1's auc: 0.826703\tvalid_1's binary_logloss: 0.135043\n",
      "[47]\ttraining's auc: 0.919365\ttraining's binary_logloss: 0.108935\tvalid_1's auc: 0.826424\tvalid_1's binary_logloss: 0.135107\n",
      "[48]\ttraining's auc: 0.919719\ttraining's binary_logloss: 0.108707\tvalid_1's auc: 0.826319\tvalid_1's binary_logloss: 0.135157\n",
      "[49]\ttraining's auc: 0.920217\ttraining's binary_logloss: 0.108423\tvalid_1's auc: 0.826291\tvalid_1's binary_logloss: 0.135159\n",
      "[50]\ttraining's auc: 0.920808\ttraining's binary_logloss: 0.108109\tvalid_1's auc: 0.826546\tvalid_1's binary_logloss: 0.135098\n",
      "[51]\ttraining's auc: 0.92172\ttraining's binary_logloss: 0.107737\tvalid_1's auc: 0.826589\tvalid_1's binary_logloss: 0.135072\n",
      "[52]\ttraining's auc: 0.922089\ttraining's binary_logloss: 0.107473\tvalid_1's auc: 0.826493\tvalid_1's binary_logloss: 0.135092\n",
      "[53]\ttraining's auc: 0.922721\ttraining's binary_logloss: 0.107176\tvalid_1's auc: 0.826332\tvalid_1's binary_logloss: 0.135126\n",
      "[54]\ttraining's auc: 0.922942\ttraining's binary_logloss: 0.106943\tvalid_1's auc: 0.82628\tvalid_1's binary_logloss: 0.135162\n",
      "[55]\ttraining's auc: 0.923487\ttraining's binary_logloss: 0.106611\tvalid_1's auc: 0.826264\tvalid_1's binary_logloss: 0.135192\n",
      "[56]\ttraining's auc: 0.923923\ttraining's binary_logloss: 0.106338\tvalid_1's auc: 0.826487\tvalid_1's binary_logloss: 0.135156\n",
      "[57]\ttraining's auc: 0.92433\ttraining's binary_logloss: 0.106136\tvalid_1's auc: 0.826498\tvalid_1's binary_logloss: 0.13518\n",
      "[58]\ttraining's auc: 0.924789\ttraining's binary_logloss: 0.10591\tvalid_1's auc: 0.826475\tvalid_1's binary_logloss: 0.135201\n",
      "[59]\ttraining's auc: 0.925126\ttraining's binary_logloss: 0.105728\tvalid_1's auc: 0.826539\tvalid_1's binary_logloss: 0.135165\n",
      "[60]\ttraining's auc: 0.925638\ttraining's binary_logloss: 0.105477\tvalid_1's auc: 0.826591\tvalid_1's binary_logloss: 0.135189\n",
      "[61]\ttraining's auc: 0.926173\ttraining's binary_logloss: 0.105232\tvalid_1's auc: 0.82652\tvalid_1's binary_logloss: 0.135206\n",
      "[62]\ttraining's auc: 0.926817\ttraining's binary_logloss: 0.104932\tvalid_1's auc: 0.826444\tvalid_1's binary_logloss: 0.135238\n",
      "[63]\ttraining's auc: 0.927053\ttraining's binary_logloss: 0.104767\tvalid_1's auc: 0.826449\tvalid_1's binary_logloss: 0.135251\n",
      "[64]\ttraining's auc: 0.927455\ttraining's binary_logloss: 0.104541\tvalid_1's auc: 0.826508\tvalid_1's binary_logloss: 0.135287\n",
      "[65]\ttraining's auc: 0.928588\ttraining's binary_logloss: 0.104234\tvalid_1's auc: 0.82642\tvalid_1's binary_logloss: 0.135315\n",
      "[66]\ttraining's auc: 0.928845\ttraining's binary_logloss: 0.104073\tvalid_1's auc: 0.826537\tvalid_1's binary_logloss: 0.135308\n",
      "[67]\ttraining's auc: 0.929051\ttraining's binary_logloss: 0.103903\tvalid_1's auc: 0.826572\tvalid_1's binary_logloss: 0.135328\n",
      "[68]\ttraining's auc: 0.92947\ttraining's binary_logloss: 0.103644\tvalid_1's auc: 0.826539\tvalid_1's binary_logloss: 0.13536\n",
      "[69]\ttraining's auc: 0.929866\ttraining's binary_logloss: 0.103404\tvalid_1's auc: 0.826718\tvalid_1's binary_logloss: 0.135339\n",
      "[70]\ttraining's auc: 0.930564\ttraining's binary_logloss: 0.103108\tvalid_1's auc: 0.826758\tvalid_1's binary_logloss: 0.135368\n",
      "[71]\ttraining's auc: 0.930822\ttraining's binary_logloss: 0.102906\tvalid_1's auc: 0.826576\tvalid_1's binary_logloss: 0.135401\n",
      "[72]\ttraining's auc: 0.930993\ttraining's binary_logloss: 0.102728\tvalid_1's auc: 0.826346\tvalid_1's binary_logloss: 0.135459\n",
      "[73]\ttraining's auc: 0.931222\ttraining's binary_logloss: 0.102569\tvalid_1's auc: 0.826137\tvalid_1's binary_logloss: 0.135524\n",
      "[74]\ttraining's auc: 0.931495\ttraining's binary_logloss: 0.10238\tvalid_1's auc: 0.826111\tvalid_1's binary_logloss: 0.135546\n",
      "[75]\ttraining's auc: 0.931818\ttraining's binary_logloss: 0.10216\tvalid_1's auc: 0.826099\tvalid_1's binary_logloss: 0.13556\n",
      "[76]\ttraining's auc: 0.932374\ttraining's binary_logloss: 0.101926\tvalid_1's auc: 0.826221\tvalid_1's binary_logloss: 0.135563\n",
      "[77]\ttraining's auc: 0.932539\ttraining's binary_logloss: 0.101781\tvalid_1's auc: 0.826186\tvalid_1's binary_logloss: 0.135559\n",
      "[78]\ttraining's auc: 0.932724\ttraining's binary_logloss: 0.101623\tvalid_1's auc: 0.826061\tvalid_1's binary_logloss: 0.135596\n",
      "[79]\ttraining's auc: 0.932916\ttraining's binary_logloss: 0.101443\tvalid_1's auc: 0.825901\tvalid_1's binary_logloss: 0.135659\n",
      "[80]\ttraining's auc: 0.933199\ttraining's binary_logloss: 0.101234\tvalid_1's auc: 0.825649\tvalid_1's binary_logloss: 0.135741\n",
      "[81]\ttraining's auc: 0.933887\ttraining's binary_logloss: 0.100961\tvalid_1's auc: 0.825574\tvalid_1's binary_logloss: 0.13577\n",
      "[82]\ttraining's auc: 0.934637\ttraining's binary_logloss: 0.100577\tvalid_1's auc: 0.825682\tvalid_1's binary_logloss: 0.135769\n",
      "[83]\ttraining's auc: 0.935193\ttraining's binary_logloss: 0.100293\tvalid_1's auc: 0.82569\tvalid_1's binary_logloss: 0.135796\n",
      "[84]\ttraining's auc: 0.935285\ttraining's binary_logloss: 0.100171\tvalid_1's auc: 0.825326\tvalid_1's binary_logloss: 0.135875\n",
      "[85]\ttraining's auc: 0.935502\ttraining's binary_logloss: 0.100022\tvalid_1's auc: 0.82529\tvalid_1's binary_logloss: 0.135911\n",
      "[86]\ttraining's auc: 0.936187\ttraining's binary_logloss: 0.0997438\tvalid_1's auc: 0.825301\tvalid_1's binary_logloss: 0.135954\n",
      "[87]\ttraining's auc: 0.936396\ttraining's binary_logloss: 0.0995565\tvalid_1's auc: 0.824985\tvalid_1's binary_logloss: 0.136051\n",
      "[88]\ttraining's auc: 0.936538\ttraining's binary_logloss: 0.0994139\tvalid_1's auc: 0.824801\tvalid_1's binary_logloss: 0.13615\n",
      "[89]\ttraining's auc: 0.936906\ttraining's binary_logloss: 0.0992136\tvalid_1's auc: 0.824759\tvalid_1's binary_logloss: 0.136208\n",
      "[90]\ttraining's auc: 0.937488\ttraining's binary_logloss: 0.0988792\tvalid_1's auc: 0.824695\tvalid_1's binary_logloss: 0.136246\n",
      "[91]\ttraining's auc: 0.937621\ttraining's binary_logloss: 0.0987331\tvalid_1's auc: 0.824554\tvalid_1's binary_logloss: 0.136313\n",
      "[92]\ttraining's auc: 0.937834\ttraining's binary_logloss: 0.0985891\tvalid_1's auc: 0.824496\tvalid_1's binary_logloss: 0.13635\n",
      "[93]\ttraining's auc: 0.938143\ttraining's binary_logloss: 0.0984237\tvalid_1's auc: 0.824418\tvalid_1's binary_logloss: 0.136388\n",
      "[94]\ttraining's auc: 0.938616\ttraining's binary_logloss: 0.0981237\tvalid_1's auc: 0.824504\tvalid_1's binary_logloss: 0.136384\n",
      "[95]\ttraining's auc: 0.939316\ttraining's binary_logloss: 0.0978728\tvalid_1's auc: 0.824511\tvalid_1's binary_logloss: 0.136408\n",
      "[96]\ttraining's auc: 0.939832\ttraining's binary_logloss: 0.0976577\tvalid_1's auc: 0.824461\tvalid_1's binary_logloss: 0.136434\n",
      "[97]\ttraining's auc: 0.939987\ttraining's binary_logloss: 0.0975284\tvalid_1's auc: 0.824381\tvalid_1's binary_logloss: 0.13645\n",
      "[98]\ttraining's auc: 0.940149\ttraining's binary_logloss: 0.0973838\tvalid_1's auc: 0.824197\tvalid_1's binary_logloss: 0.136516\n",
      "[99]\ttraining's auc: 0.940382\ttraining's binary_logloss: 0.0971879\tvalid_1's auc: 0.823944\tvalid_1's binary_logloss: 0.136587\n",
      "[100]\ttraining's auc: 0.940567\ttraining's binary_logloss: 0.0970557\tvalid_1's auc: 0.823834\tvalid_1's binary_logloss: 0.136615\n",
      "[101]\ttraining's auc: 0.940935\ttraining's binary_logloss: 0.0968374\tvalid_1's auc: 0.823939\tvalid_1's binary_logloss: 0.136621\n",
      "[102]\ttraining's auc: 0.94139\ttraining's binary_logloss: 0.0966439\tvalid_1's auc: 0.824186\tvalid_1's binary_logloss: 0.136623\n",
      "[103]\ttraining's auc: 0.941711\ttraining's binary_logloss: 0.0964178\tvalid_1's auc: 0.824309\tvalid_1's binary_logloss: 0.136627\n",
      "[104]\ttraining's auc: 0.942001\ttraining's binary_logloss: 0.0962212\tvalid_1's auc: 0.82407\tvalid_1's binary_logloss: 0.136696\n",
      "[105]\ttraining's auc: 0.942104\ttraining's binary_logloss: 0.0961142\tvalid_1's auc: 0.823842\tvalid_1's binary_logloss: 0.136762\n",
      "[106]\ttraining's auc: 0.942211\ttraining's binary_logloss: 0.0959897\tvalid_1's auc: 0.823921\tvalid_1's binary_logloss: 0.136754\n",
      "[107]\ttraining's auc: 0.942462\ttraining's binary_logloss: 0.0958488\tvalid_1's auc: 0.824099\tvalid_1's binary_logloss: 0.136755\n",
      "[108]\ttraining's auc: 0.942716\ttraining's binary_logloss: 0.0956495\tvalid_1's auc: 0.823996\tvalid_1's binary_logloss: 0.136801\n",
      "[109]\ttraining's auc: 0.942945\ttraining's binary_logloss: 0.0955004\tvalid_1's auc: 0.823933\tvalid_1's binary_logloss: 0.13683\n",
      "[110]\ttraining's auc: 0.943329\ttraining's binary_logloss: 0.0952326\tvalid_1's auc: 0.823976\tvalid_1's binary_logloss: 0.136843\n",
      "[111]\ttraining's auc: 0.943593\ttraining's binary_logloss: 0.0949995\tvalid_1's auc: 0.824082\tvalid_1's binary_logloss: 0.136866\n",
      "[112]\ttraining's auc: 0.943674\ttraining's binary_logloss: 0.0948912\tvalid_1's auc: 0.823913\tvalid_1's binary_logloss: 0.136927\n",
      "[113]\ttraining's auc: 0.9439\ttraining's binary_logloss: 0.0947012\tvalid_1's auc: 0.823994\tvalid_1's binary_logloss: 0.136918\n",
      "[114]\ttraining's auc: 0.943976\ttraining's binary_logloss: 0.0946048\tvalid_1's auc: 0.823982\tvalid_1's binary_logloss: 0.136945\n",
      "[115]\ttraining's auc: 0.944066\ttraining's binary_logloss: 0.0944885\tvalid_1's auc: 0.824237\tvalid_1's binary_logloss: 0.136933\n",
      "[116]\ttraining's auc: 0.944362\ttraining's binary_logloss: 0.0942551\tvalid_1's auc: 0.824116\tvalid_1's binary_logloss: 0.136981\n",
      "[117]\ttraining's auc: 0.944825\ttraining's binary_logloss: 0.0940189\tvalid_1's auc: 0.824145\tvalid_1's binary_logloss: 0.136993\n",
      "[118]\ttraining's auc: 0.945175\ttraining's binary_logloss: 0.0938378\tvalid_1's auc: 0.824073\tvalid_1's binary_logloss: 0.137037\n",
      "[119]\ttraining's auc: 0.945766\ttraining's binary_logloss: 0.0936074\tvalid_1's auc: 0.823898\tvalid_1's binary_logloss: 0.137077\n",
      "[120]\ttraining's auc: 0.945875\ttraining's binary_logloss: 0.0934942\tvalid_1's auc: 0.823633\tvalid_1's binary_logloss: 0.137169\n",
      "[121]\ttraining's auc: 0.94612\ttraining's binary_logloss: 0.0933214\tvalid_1's auc: 0.823634\tvalid_1's binary_logloss: 0.137205\n",
      "[122]\ttraining's auc: 0.946287\ttraining's binary_logloss: 0.0931779\tvalid_1's auc: 0.823713\tvalid_1's binary_logloss: 0.137209\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's auc: 0.891328\ttraining's binary_logloss: 0.119957\tvalid_1's auc: 0.826818\tvalid_1's binary_logloss: 0.135039\n",
      "ROC AUC: {0:.4f} 0.842778796585179\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_clf = LGBMClassifier(n_estimators = 500)\n",
    "\n",
    "eval_set = [(X_tr, y_tr), (X_val, y_val)]\n",
    "lgbm_clf.fit(X_tr, y_tr, early_stopping_rounds = 100, eval_metric=\"auc\", eval_set = eval_set)\n",
    "lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:,1])\n",
    "print('ROC AUC: {0:.4f}',format(lgbm_roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af76aad0-2611-4b63-bfe4-9a773be4506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperOpt를 이용해 베이지안 최적화 기반으로 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4754fbd4-a229-452b-9f14-388936c7c159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76134cdf-7961-4fd1-9feb-4410bc4e55aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "lgbm_search_space = {'num_leaves': hp.quniform('num_leaves', 32, 64, 1),\n",
    "                    'max_depth': hp.quniform('max_depth', 100, 160, 1),\n",
    "                   'min_child_weight': hp.quniform('min_child_weight', 60, 100, 1),\n",
    "                   'subsample': hp.quniform('subsample', 0.7, 1),\n",
    "                   'lelarning_rate': hp.quniform('learning_rate',0.01,0.2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e59e32-b265-430d-990a-972df4eed295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2b279d81-925c-4c81-9267-4be3c50812a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.155041\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.157576\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\ttraining's auc: 0.834033\ttraining's binary_logloss: 0.149345\tvalid_1's auc: 0.808708\tvalid_1's binary_logloss: 0.153044\n",
      "[3]\ttraining's auc: 0.842615\ttraining's binary_logloss: 0.145266\tvalid_1's auc: 0.815718\tvalid_1's binary_logloss: 0.149908\n",
      "[4]\ttraining's auc: 0.847162\ttraining's binary_logloss: 0.142008\tvalid_1's auc: 0.817273\tvalid_1's binary_logloss: 0.147595\n",
      "[5]\ttraining's auc: 0.850571\ttraining's binary_logloss: 0.139293\tvalid_1's auc: 0.81865\tvalid_1's binary_logloss: 0.145715\n",
      "[6]\ttraining's auc: 0.852997\ttraining's binary_logloss: 0.137037\tvalid_1's auc: 0.81958\tvalid_1's binary_logloss: 0.144191\n",
      "[7]\ttraining's auc: 0.857308\ttraining's binary_logloss: 0.135138\tvalid_1's auc: 0.820111\tvalid_1's binary_logloss: 0.142894\n",
      "[8]\ttraining's auc: 0.859915\ttraining's binary_logloss: 0.133354\tvalid_1's auc: 0.82164\tvalid_1's binary_logloss: 0.141735\n",
      "[9]\ttraining's auc: 0.863044\ttraining's binary_logloss: 0.131908\tvalid_1's auc: 0.823657\tvalid_1's binary_logloss: 0.140799\n",
      "[10]\ttraining's auc: 0.864785\ttraining's binary_logloss: 0.130613\tvalid_1's auc: 0.82509\tvalid_1's binary_logloss: 0.139951\n",
      "[11]\ttraining's auc: 0.867449\ttraining's binary_logloss: 0.129448\tvalid_1's auc: 0.825695\tvalid_1's binary_logloss: 0.139384\n",
      "[12]\ttraining's auc: 0.870206\ttraining's binary_logloss: 0.128367\tvalid_1's auc: 0.826127\tvalid_1's binary_logloss: 0.138923\n",
      "[13]\ttraining's auc: 0.871961\ttraining's binary_logloss: 0.12737\tvalid_1's auc: 0.826038\tvalid_1's binary_logloss: 0.138548\n",
      "[14]\ttraining's auc: 0.873415\ttraining's binary_logloss: 0.126536\tvalid_1's auc: 0.826119\tvalid_1's binary_logloss: 0.138172\n",
      "[15]\ttraining's auc: 0.875117\ttraining's binary_logloss: 0.125648\tvalid_1's auc: 0.826846\tvalid_1's binary_logloss: 0.137713\n",
      "[16]\ttraining's auc: 0.876275\ttraining's binary_logloss: 0.1249\tvalid_1's auc: 0.827389\tvalid_1's binary_logloss: 0.137398\n",
      "[17]\ttraining's auc: 0.878002\ttraining's binary_logloss: 0.124163\tvalid_1's auc: 0.828346\tvalid_1's binary_logloss: 0.137182\n",
      "[18]\ttraining's auc: 0.881899\ttraining's binary_logloss: 0.123292\tvalid_1's auc: 0.828323\tvalid_1's binary_logloss: 0.136974\n",
      "[19]\ttraining's auc: 0.883398\ttraining's binary_logloss: 0.122658\tvalid_1's auc: 0.82815\tvalid_1's binary_logloss: 0.136884\n",
      "[20]\ttraining's auc: 0.884821\ttraining's binary_logloss: 0.122039\tvalid_1's auc: 0.828302\tvalid_1's binary_logloss: 0.13674\n",
      "[21]\ttraining's auc: 0.885971\ttraining's binary_logloss: 0.121433\tvalid_1's auc: 0.827874\tvalid_1's binary_logloss: 0.136725\n",
      "[22]\ttraining's auc: 0.887881\ttraining's binary_logloss: 0.120754\tvalid_1's auc: 0.828049\tvalid_1's binary_logloss: 0.136679\n",
      "[23]\ttraining's auc: 0.889327\ttraining's binary_logloss: 0.120147\tvalid_1's auc: 0.827727\tvalid_1's binary_logloss: 0.136633\n",
      "[24]\ttraining's auc: 0.8903\ttraining's binary_logloss: 0.119651\tvalid_1's auc: 0.827937\tvalid_1's binary_logloss: 0.13657\n",
      "[25]\ttraining's auc: 0.891399\ttraining's binary_logloss: 0.119183\tvalid_1's auc: 0.827662\tvalid_1's binary_logloss: 0.136548\n",
      "[26]\ttraining's auc: 0.893562\ttraining's binary_logloss: 0.118602\tvalid_1's auc: 0.82806\tvalid_1's binary_logloss: 0.136449\n",
      "[27]\ttraining's auc: 0.895502\ttraining's binary_logloss: 0.118154\tvalid_1's auc: 0.828085\tvalid_1's binary_logloss: 0.136416\n",
      "[28]\ttraining's auc: 0.896658\ttraining's binary_logloss: 0.117679\tvalid_1's auc: 0.827698\tvalid_1's binary_logloss: 0.13648\n",
      "[29]\ttraining's auc: 0.897792\ttraining's binary_logloss: 0.117191\tvalid_1's auc: 0.827764\tvalid_1's binary_logloss: 0.136475\n",
      "[30]\ttraining's auc: 0.899142\ttraining's binary_logloss: 0.116719\tvalid_1's auc: 0.828225\tvalid_1's binary_logloss: 0.136353\n",
      "[31]\ttraining's auc: 0.90016\ttraining's binary_logloss: 0.116339\tvalid_1's auc: 0.828499\tvalid_1's binary_logloss: 0.136316\n",
      "[32]\ttraining's auc: 0.901984\ttraining's binary_logloss: 0.11585\tvalid_1's auc: 0.829103\tvalid_1's binary_logloss: 0.136182\n",
      "[33]\ttraining's auc: 0.903015\ttraining's binary_logloss: 0.115419\tvalid_1's auc: 0.828837\tvalid_1's binary_logloss: 0.136236\n",
      "[34]\ttraining's auc: 0.903797\ttraining's binary_logloss: 0.115044\tvalid_1's auc: 0.828501\tvalid_1's binary_logloss: 0.136283\n",
      "[35]\ttraining's auc: 0.905178\ttraining's binary_logloss: 0.11464\tvalid_1's auc: 0.828358\tvalid_1's binary_logloss: 0.136315\n",
      "[36]\ttraining's auc: 0.905977\ttraining's binary_logloss: 0.114235\tvalid_1's auc: 0.828362\tvalid_1's binary_logloss: 0.136319\n",
      "[37]\ttraining's auc: 0.906798\ttraining's binary_logloss: 0.113914\tvalid_1's auc: 0.828289\tvalid_1's binary_logloss: 0.136335\n",
      "[38]\ttraining's auc: 0.907408\ttraining's binary_logloss: 0.113586\tvalid_1's auc: 0.828487\tvalid_1's binary_logloss: 0.136338\n",
      "[39]\ttraining's auc: 0.908209\ttraining's binary_logloss: 0.113186\tvalid_1's auc: 0.828683\tvalid_1's binary_logloss: 0.136307\n",
      "[40]\ttraining's auc: 0.908821\ttraining's binary_logloss: 0.112882\tvalid_1's auc: 0.828481\tvalid_1's binary_logloss: 0.13637\n",
      "[41]\ttraining's auc: 0.909623\ttraining's binary_logloss: 0.112525\tvalid_1's auc: 0.828556\tvalid_1's binary_logloss: 0.136369\n",
      "[42]\ttraining's auc: 0.910212\ttraining's binary_logloss: 0.11229\tvalid_1's auc: 0.828355\tvalid_1's binary_logloss: 0.136385\n",
      "[43]\ttraining's auc: 0.91092\ttraining's binary_logloss: 0.111947\tvalid_1's auc: 0.828139\tvalid_1's binary_logloss: 0.136439\n",
      "[44]\ttraining's auc: 0.911592\ttraining's binary_logloss: 0.111656\tvalid_1's auc: 0.828079\tvalid_1's binary_logloss: 0.136486\n",
      "[45]\ttraining's auc: 0.912324\ttraining's binary_logloss: 0.111354\tvalid_1's auc: 0.827918\tvalid_1's binary_logloss: 0.136506\n",
      "[46]\ttraining's auc: 0.913173\ttraining's binary_logloss: 0.11098\tvalid_1's auc: 0.827541\tvalid_1's binary_logloss: 0.136601\n",
      "[47]\ttraining's auc: 0.914155\ttraining's binary_logloss: 0.110584\tvalid_1's auc: 0.827198\tvalid_1's binary_logloss: 0.136687\n",
      "[48]\ttraining's auc: 0.914599\ttraining's binary_logloss: 0.110357\tvalid_1's auc: 0.827079\tvalid_1's binary_logloss: 0.136709\n",
      "[49]\ttraining's auc: 0.915488\ttraining's binary_logloss: 0.110094\tvalid_1's auc: 0.826995\tvalid_1's binary_logloss: 0.136744\n",
      "[50]\ttraining's auc: 0.916024\ttraining's binary_logloss: 0.10982\tvalid_1's auc: 0.82681\tvalid_1's binary_logloss: 0.136781\n",
      "[51]\ttraining's auc: 0.916929\ttraining's binary_logloss: 0.109432\tvalid_1's auc: 0.826231\tvalid_1's binary_logloss: 0.136928\n",
      "[52]\ttraining's auc: 0.917474\ttraining's binary_logloss: 0.109123\tvalid_1's auc: 0.826182\tvalid_1's binary_logloss: 0.136945\n",
      "[53]\ttraining's auc: 0.917952\ttraining's binary_logloss: 0.108875\tvalid_1's auc: 0.825845\tvalid_1's binary_logloss: 0.137057\n",
      "[54]\ttraining's auc: 0.918239\ttraining's binary_logloss: 0.108693\tvalid_1's auc: 0.825588\tvalid_1's binary_logloss: 0.13712\n",
      "[55]\ttraining's auc: 0.918459\ttraining's binary_logloss: 0.108511\tvalid_1's auc: 0.825347\tvalid_1's binary_logloss: 0.137167\n",
      "[56]\ttraining's auc: 0.918661\ttraining's binary_logloss: 0.108351\tvalid_1's auc: 0.825154\tvalid_1's binary_logloss: 0.137213\n",
      "[57]\ttraining's auc: 0.919016\ttraining's binary_logloss: 0.108118\tvalid_1's auc: 0.824664\tvalid_1's binary_logloss: 0.13731\n",
      "[58]\ttraining's auc: 0.919607\ttraining's binary_logloss: 0.10784\tvalid_1's auc: 0.824523\tvalid_1's binary_logloss: 0.137318\n",
      "[59]\ttraining's auc: 0.919909\ttraining's binary_logloss: 0.107667\tvalid_1's auc: 0.824349\tvalid_1's binary_logloss: 0.137353\n",
      "[60]\ttraining's auc: 0.920178\ttraining's binary_logloss: 0.107506\tvalid_1's auc: 0.824097\tvalid_1's binary_logloss: 0.137443\n",
      "[61]\ttraining's auc: 0.920338\ttraining's binary_logloss: 0.107361\tvalid_1's auc: 0.823798\tvalid_1's binary_logloss: 0.137543\n",
      "[62]\ttraining's auc: 0.920945\ttraining's binary_logloss: 0.107062\tvalid_1's auc: 0.823717\tvalid_1's binary_logloss: 0.137567\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's auc: 0.901984\ttraining's binary_logloss: 0.11585\tvalid_1's auc: 0.829103\tvalid_1's binary_logloss: 0.136182\n",
      "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.157465\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.153522\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\ttraining's auc: 0.828301\ttraining's binary_logloss: 0.151771\tvalid_1's auc: 0.814899\tvalid_1's binary_logloss: 0.149172\n",
      "[3]\ttraining's auc: 0.83779\ttraining's binary_logloss: 0.147521\tvalid_1's auc: 0.818762\tvalid_1's binary_logloss: 0.14603\n",
      "[4]\ttraining's auc: 0.844309\ttraining's binary_logloss: 0.144223\tvalid_1's auc: 0.824382\tvalid_1's binary_logloss: 0.143608\n",
      "[5]\ttraining's auc: 0.848847\ttraining's binary_logloss: 0.14149\tvalid_1's auc: 0.826658\tvalid_1's binary_logloss: 0.141625\n",
      "[6]\ttraining's auc: 0.852026\ttraining's binary_logloss: 0.139153\tvalid_1's auc: 0.829266\tvalid_1's binary_logloss: 0.140003\n",
      "[7]\ttraining's auc: 0.854508\ttraining's binary_logloss: 0.13717\tvalid_1's auc: 0.83065\tvalid_1's binary_logloss: 0.138685\n",
      "[8]\ttraining's auc: 0.857838\ttraining's binary_logloss: 0.135446\tvalid_1's auc: 0.830431\tvalid_1's binary_logloss: 0.1377\n",
      "[9]\ttraining's auc: 0.86026\ttraining's binary_logloss: 0.133891\tvalid_1's auc: 0.830167\tvalid_1's binary_logloss: 0.136821\n",
      "[10]\ttraining's auc: 0.864926\ttraining's binary_logloss: 0.132464\tvalid_1's auc: 0.831906\tvalid_1's binary_logloss: 0.136013\n",
      "[11]\ttraining's auc: 0.868162\ttraining's binary_logloss: 0.131234\tvalid_1's auc: 0.832223\tvalid_1's binary_logloss: 0.13536\n",
      "[12]\ttraining's auc: 0.870716\ttraining's binary_logloss: 0.130103\tvalid_1's auc: 0.832057\tvalid_1's binary_logloss: 0.134899\n",
      "[13]\ttraining's auc: 0.871751\ttraining's binary_logloss: 0.1291\tvalid_1's auc: 0.832517\tvalid_1's binary_logloss: 0.134388\n",
      "[14]\ttraining's auc: 0.872618\ttraining's binary_logloss: 0.128202\tvalid_1's auc: 0.832183\tvalid_1's binary_logloss: 0.134028\n",
      "[15]\ttraining's auc: 0.874484\ttraining's binary_logloss: 0.127319\tvalid_1's auc: 0.832188\tvalid_1's binary_logloss: 0.133689\n",
      "[16]\ttraining's auc: 0.876709\ttraining's binary_logloss: 0.126518\tvalid_1's auc: 0.833105\tvalid_1's binary_logloss: 0.133401\n",
      "[17]\ttraining's auc: 0.879008\ttraining's binary_logloss: 0.125709\tvalid_1's auc: 0.832909\tvalid_1's binary_logloss: 0.13309\n",
      "[18]\ttraining's auc: 0.879756\ttraining's binary_logloss: 0.125011\tvalid_1's auc: 0.832981\tvalid_1's binary_logloss: 0.132867\n",
      "[19]\ttraining's auc: 0.88199\ttraining's binary_logloss: 0.124281\tvalid_1's auc: 0.832712\tvalid_1's binary_logloss: 0.132742\n",
      "[20]\ttraining's auc: 0.883669\ttraining's binary_logloss: 0.123687\tvalid_1's auc: 0.832674\tvalid_1's binary_logloss: 0.13261\n",
      "[21]\ttraining's auc: 0.885177\ttraining's binary_logloss: 0.123091\tvalid_1's auc: 0.832396\tvalid_1's binary_logloss: 0.132507\n",
      "[22]\ttraining's auc: 0.886175\ttraining's binary_logloss: 0.122512\tvalid_1's auc: 0.832973\tvalid_1's binary_logloss: 0.132355\n",
      "[23]\ttraining's auc: 0.887543\ttraining's binary_logloss: 0.121992\tvalid_1's auc: 0.832676\tvalid_1's binary_logloss: 0.132307\n",
      "[24]\ttraining's auc: 0.888861\ttraining's binary_logloss: 0.12147\tvalid_1's auc: 0.832962\tvalid_1's binary_logloss: 0.132221\n",
      "[25]\ttraining's auc: 0.890202\ttraining's binary_logloss: 0.120956\tvalid_1's auc: 0.83354\tvalid_1's binary_logloss: 0.132081\n",
      "[26]\ttraining's auc: 0.89174\ttraining's binary_logloss: 0.120419\tvalid_1's auc: 0.833177\tvalid_1's binary_logloss: 0.13203\n",
      "[27]\ttraining's auc: 0.892602\ttraining's binary_logloss: 0.119973\tvalid_1's auc: 0.832926\tvalid_1's binary_logloss: 0.132007\n",
      "[28]\ttraining's auc: 0.893241\ttraining's binary_logloss: 0.119559\tvalid_1's auc: 0.8336\tvalid_1's binary_logloss: 0.131854\n",
      "[29]\ttraining's auc: 0.894755\ttraining's binary_logloss: 0.119141\tvalid_1's auc: 0.833506\tvalid_1's binary_logloss: 0.131815\n",
      "[30]\ttraining's auc: 0.896309\ttraining's binary_logloss: 0.118698\tvalid_1's auc: 0.833729\tvalid_1's binary_logloss: 0.131774\n",
      "[31]\ttraining's auc: 0.897804\ttraining's binary_logloss: 0.118243\tvalid_1's auc: 0.833756\tvalid_1's binary_logloss: 0.131703\n",
      "[32]\ttraining's auc: 0.898406\ttraining's binary_logloss: 0.117873\tvalid_1's auc: 0.833686\tvalid_1's binary_logloss: 0.131676\n",
      "[33]\ttraining's auc: 0.900047\ttraining's binary_logloss: 0.117461\tvalid_1's auc: 0.833321\tvalid_1's binary_logloss: 0.131705\n",
      "[34]\ttraining's auc: 0.901776\ttraining's binary_logloss: 0.116992\tvalid_1's auc: 0.833435\tvalid_1's binary_logloss: 0.131692\n",
      "[35]\ttraining's auc: 0.902523\ttraining's binary_logloss: 0.116624\tvalid_1's auc: 0.833465\tvalid_1's binary_logloss: 0.13168\n",
      "[36]\ttraining's auc: 0.903892\ttraining's binary_logloss: 0.116162\tvalid_1's auc: 0.833443\tvalid_1's binary_logloss: 0.131674\n",
      "[37]\ttraining's auc: 0.904558\ttraining's binary_logloss: 0.115766\tvalid_1's auc: 0.833263\tvalid_1's binary_logloss: 0.131686\n",
      "[38]\ttraining's auc: 0.905519\ttraining's binary_logloss: 0.115337\tvalid_1's auc: 0.832918\tvalid_1's binary_logloss: 0.131746\n",
      "[39]\ttraining's auc: 0.906334\ttraining's binary_logloss: 0.115031\tvalid_1's auc: 0.832778\tvalid_1's binary_logloss: 0.131757\n",
      "[40]\ttraining's auc: 0.907038\ttraining's binary_logloss: 0.114651\tvalid_1's auc: 0.832823\tvalid_1's binary_logloss: 0.13175\n",
      "[41]\ttraining's auc: 0.907801\ttraining's binary_logloss: 0.114296\tvalid_1's auc: 0.83335\tvalid_1's binary_logloss: 0.131662\n",
      "[42]\ttraining's auc: 0.908421\ttraining's binary_logloss: 0.113976\tvalid_1's auc: 0.833217\tvalid_1's binary_logloss: 0.131681\n",
      "[43]\ttraining's auc: 0.909004\ttraining's binary_logloss: 0.113625\tvalid_1's auc: 0.833193\tvalid_1's binary_logloss: 0.13168\n",
      "[44]\ttraining's auc: 0.90988\ttraining's binary_logloss: 0.113302\tvalid_1's auc: 0.83314\tvalid_1's binary_logloss: 0.131699\n",
      "[45]\ttraining's auc: 0.910394\ttraining's binary_logloss: 0.113028\tvalid_1's auc: 0.833494\tvalid_1's binary_logloss: 0.131642\n",
      "[46]\ttraining's auc: 0.91088\ttraining's binary_logloss: 0.112723\tvalid_1's auc: 0.833706\tvalid_1's binary_logloss: 0.131626\n",
      "[47]\ttraining's auc: 0.911483\ttraining's binary_logloss: 0.112431\tvalid_1's auc: 0.833645\tvalid_1's binary_logloss: 0.131583\n",
      "[48]\ttraining's auc: 0.912666\ttraining's binary_logloss: 0.111975\tvalid_1's auc: 0.833508\tvalid_1's binary_logloss: 0.131601\n",
      "[49]\ttraining's auc: 0.913167\ttraining's binary_logloss: 0.111657\tvalid_1's auc: 0.833114\tvalid_1's binary_logloss: 0.131664\n",
      "[50]\ttraining's auc: 0.913732\ttraining's binary_logloss: 0.111417\tvalid_1's auc: 0.83313\tvalid_1's binary_logloss: 0.131669\n",
      "[51]\ttraining's auc: 0.914884\ttraining's binary_logloss: 0.111008\tvalid_1's auc: 0.832931\tvalid_1's binary_logloss: 0.131728\n",
      "[52]\ttraining's auc: 0.915201\ttraining's binary_logloss: 0.110806\tvalid_1's auc: 0.832692\tvalid_1's binary_logloss: 0.13177\n",
      "[53]\ttraining's auc: 0.915601\ttraining's binary_logloss: 0.110578\tvalid_1's auc: 0.832452\tvalid_1's binary_logloss: 0.131803\n",
      "[54]\ttraining's auc: 0.916531\ttraining's binary_logloss: 0.110274\tvalid_1's auc: 0.832239\tvalid_1's binary_logloss: 0.131834\n",
      "[55]\ttraining's auc: 0.916886\ttraining's binary_logloss: 0.110063\tvalid_1's auc: 0.832235\tvalid_1's binary_logloss: 0.131829\n",
      "[56]\ttraining's auc: 0.917295\ttraining's binary_logloss: 0.109822\tvalid_1's auc: 0.83236\tvalid_1's binary_logloss: 0.131803\n",
      "[57]\ttraining's auc: 0.917487\ttraining's binary_logloss: 0.10965\tvalid_1's auc: 0.832201\tvalid_1's binary_logloss: 0.131838\n",
      "[58]\ttraining's auc: 0.917923\ttraining's binary_logloss: 0.109409\tvalid_1's auc: 0.832222\tvalid_1's binary_logloss: 0.131835\n",
      "[59]\ttraining's auc: 0.918587\ttraining's binary_logloss: 0.109186\tvalid_1's auc: 0.832622\tvalid_1's binary_logloss: 0.131815\n",
      "[60]\ttraining's auc: 0.918998\ttraining's binary_logloss: 0.108954\tvalid_1's auc: 0.832379\tvalid_1's binary_logloss: 0.131868\n",
      "[61]\ttraining's auc: 0.919275\ttraining's binary_logloss: 0.108744\tvalid_1's auc: 0.832011\tvalid_1's binary_logloss: 0.131921\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's auc: 0.897804\ttraining's binary_logloss: 0.118243\tvalid_1's auc: 0.833756\tvalid_1's binary_logloss: 0.131703\n",
      "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.154181\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.160502\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\ttraining's auc: 0.832651\ttraining's binary_logloss: 0.148605\tvalid_1's auc: 0.815296\tvalid_1's binary_logloss: 0.155502\n",
      "[3]\ttraining's auc: 0.840128\ttraining's binary_logloss: 0.144514\tvalid_1's auc: 0.820937\tvalid_1's binary_logloss: 0.152001\n",
      "[4]\ttraining's auc: 0.844863\ttraining's binary_logloss: 0.141345\tvalid_1's auc: 0.822708\tvalid_1's binary_logloss: 0.149418\n",
      "[5]\ttraining's auc: 0.849989\ttraining's binary_logloss: 0.138589\tvalid_1's auc: 0.826011\tvalid_1's binary_logloss: 0.147284\n",
      "[6]\ttraining's auc: 0.852259\ttraining's binary_logloss: 0.136332\tvalid_1's auc: 0.827622\tvalid_1's binary_logloss: 0.14558\n",
      "[7]\ttraining's auc: 0.854795\ttraining's binary_logloss: 0.134475\tvalid_1's auc: 0.829108\tvalid_1's binary_logloss: 0.144172\n",
      "[8]\ttraining's auc: 0.857144\ttraining's binary_logloss: 0.132812\tvalid_1's auc: 0.829819\tvalid_1's binary_logloss: 0.143019\n",
      "[9]\ttraining's auc: 0.860313\ttraining's binary_logloss: 0.131295\tvalid_1's auc: 0.830712\tvalid_1's binary_logloss: 0.14204\n",
      "[10]\ttraining's auc: 0.862724\ttraining's binary_logloss: 0.130008\tvalid_1's auc: 0.830942\tvalid_1's binary_logloss: 0.141218\n",
      "[11]\ttraining's auc: 0.866752\ttraining's binary_logloss: 0.128782\tvalid_1's auc: 0.831874\tvalid_1's binary_logloss: 0.140417\n",
      "[12]\ttraining's auc: 0.869292\ttraining's binary_logloss: 0.127709\tvalid_1's auc: 0.83411\tvalid_1's binary_logloss: 0.139794\n",
      "[13]\ttraining's auc: 0.871185\ttraining's binary_logloss: 0.126738\tvalid_1's auc: 0.833584\tvalid_1's binary_logloss: 0.139385\n",
      "[14]\ttraining's auc: 0.873017\ttraining's binary_logloss: 0.125862\tvalid_1's auc: 0.834185\tvalid_1's binary_logloss: 0.138922\n",
      "[15]\ttraining's auc: 0.87419\ttraining's binary_logloss: 0.125098\tvalid_1's auc: 0.835067\tvalid_1's binary_logloss: 0.138568\n",
      "[16]\ttraining's auc: 0.876839\ttraining's binary_logloss: 0.124225\tvalid_1's auc: 0.835246\tvalid_1's binary_logloss: 0.138257\n",
      "[17]\ttraining's auc: 0.878966\ttraining's binary_logloss: 0.123466\tvalid_1's auc: 0.835123\tvalid_1's binary_logloss: 0.138103\n",
      "[18]\ttraining's auc: 0.880889\ttraining's binary_logloss: 0.122782\tvalid_1's auc: 0.835477\tvalid_1's binary_logloss: 0.137809\n",
      "[19]\ttraining's auc: 0.88293\ttraining's binary_logloss: 0.122076\tvalid_1's auc: 0.835255\tvalid_1's binary_logloss: 0.137542\n",
      "[20]\ttraining's auc: 0.884898\ttraining's binary_logloss: 0.12133\tvalid_1's auc: 0.83485\tvalid_1's binary_logloss: 0.137489\n",
      "[21]\ttraining's auc: 0.886866\ttraining's binary_logloss: 0.120662\tvalid_1's auc: 0.835163\tvalid_1's binary_logloss: 0.137311\n",
      "[22]\ttraining's auc: 0.88793\ttraining's binary_logloss: 0.120104\tvalid_1's auc: 0.835674\tvalid_1's binary_logloss: 0.137095\n",
      "[23]\ttraining's auc: 0.889169\ttraining's binary_logloss: 0.119563\tvalid_1's auc: 0.835309\tvalid_1's binary_logloss: 0.137028\n",
      "[24]\ttraining's auc: 0.891126\ttraining's binary_logloss: 0.118894\tvalid_1's auc: 0.835379\tvalid_1's binary_logloss: 0.136985\n",
      "[25]\ttraining's auc: 0.89292\ttraining's binary_logloss: 0.118365\tvalid_1's auc: 0.835097\tvalid_1's binary_logloss: 0.136933\n",
      "[26]\ttraining's auc: 0.893712\ttraining's binary_logloss: 0.117948\tvalid_1's auc: 0.834814\tvalid_1's binary_logloss: 0.136901\n",
      "[27]\ttraining's auc: 0.895522\ttraining's binary_logloss: 0.11742\tvalid_1's auc: 0.834499\tvalid_1's binary_logloss: 0.136874\n",
      "[28]\ttraining's auc: 0.896344\ttraining's binary_logloss: 0.116933\tvalid_1's auc: 0.834855\tvalid_1's binary_logloss: 0.13673\n",
      "[29]\ttraining's auc: 0.897385\ttraining's binary_logloss: 0.11649\tvalid_1's auc: 0.834441\tvalid_1's binary_logloss: 0.136736\n",
      "[30]\ttraining's auc: 0.898545\ttraining's binary_logloss: 0.116075\tvalid_1's auc: 0.834646\tvalid_1's binary_logloss: 0.136698\n",
      "[31]\ttraining's auc: 0.90001\ttraining's binary_logloss: 0.115547\tvalid_1's auc: 0.834426\tvalid_1's binary_logloss: 0.136705\n",
      "[32]\ttraining's auc: 0.900994\ttraining's binary_logloss: 0.115132\tvalid_1's auc: 0.834091\tvalid_1's binary_logloss: 0.136758\n",
      "[33]\ttraining's auc: 0.902359\ttraining's binary_logloss: 0.114738\tvalid_1's auc: 0.834194\tvalid_1's binary_logloss: 0.136742\n",
      "[34]\ttraining's auc: 0.903069\ttraining's binary_logloss: 0.114322\tvalid_1's auc: 0.834265\tvalid_1's binary_logloss: 0.13666\n",
      "[35]\ttraining's auc: 0.904383\ttraining's binary_logloss: 0.113825\tvalid_1's auc: 0.834251\tvalid_1's binary_logloss: 0.136621\n",
      "[36]\ttraining's auc: 0.90558\ttraining's binary_logloss: 0.113409\tvalid_1's auc: 0.834263\tvalid_1's binary_logloss: 0.136626\n",
      "[37]\ttraining's auc: 0.906506\ttraining's binary_logloss: 0.113088\tvalid_1's auc: 0.834376\tvalid_1's binary_logloss: 0.136582\n",
      "[38]\ttraining's auc: 0.907841\ttraining's binary_logloss: 0.112632\tvalid_1's auc: 0.834335\tvalid_1's binary_logloss: 0.136652\n",
      "[39]\ttraining's auc: 0.908834\ttraining's binary_logloss: 0.112244\tvalid_1's auc: 0.834652\tvalid_1's binary_logloss: 0.136616\n",
      "[40]\ttraining's auc: 0.909516\ttraining's binary_logloss: 0.111916\tvalid_1's auc: 0.834471\tvalid_1's binary_logloss: 0.136683\n",
      "[41]\ttraining's auc: 0.910352\ttraining's binary_logloss: 0.111571\tvalid_1's auc: 0.835273\tvalid_1's binary_logloss: 0.136581\n",
      "[42]\ttraining's auc: 0.911251\ttraining's binary_logloss: 0.111202\tvalid_1's auc: 0.83571\tvalid_1's binary_logloss: 0.136521\n",
      "[43]\ttraining's auc: 0.911903\ttraining's binary_logloss: 0.110868\tvalid_1's auc: 0.836139\tvalid_1's binary_logloss: 0.136513\n",
      "[44]\ttraining's auc: 0.912542\ttraining's binary_logloss: 0.110537\tvalid_1's auc: 0.836344\tvalid_1's binary_logloss: 0.136493\n",
      "[45]\ttraining's auc: 0.913311\ttraining's binary_logloss: 0.110211\tvalid_1's auc: 0.836336\tvalid_1's binary_logloss: 0.136516\n",
      "[46]\ttraining's auc: 0.913891\ttraining's binary_logloss: 0.109942\tvalid_1's auc: 0.836522\tvalid_1's binary_logloss: 0.136485\n",
      "[47]\ttraining's auc: 0.914506\ttraining's binary_logloss: 0.10964\tvalid_1's auc: 0.836631\tvalid_1's binary_logloss: 0.136462\n",
      "[48]\ttraining's auc: 0.915083\ttraining's binary_logloss: 0.109369\tvalid_1's auc: 0.83624\tvalid_1's binary_logloss: 0.136541\n",
      "[49]\ttraining's auc: 0.915647\ttraining's binary_logloss: 0.109106\tvalid_1's auc: 0.836224\tvalid_1's binary_logloss: 0.136566\n",
      "[50]\ttraining's auc: 0.916114\ttraining's binary_logloss: 0.10884\tvalid_1's auc: 0.83577\tvalid_1's binary_logloss: 0.136677\n",
      "[51]\ttraining's auc: 0.917003\ttraining's binary_logloss: 0.108537\tvalid_1's auc: 0.835785\tvalid_1's binary_logloss: 0.136675\n",
      "[52]\ttraining's auc: 0.917678\ttraining's binary_logloss: 0.108192\tvalid_1's auc: 0.83585\tvalid_1's binary_logloss: 0.136672\n",
      "[53]\ttraining's auc: 0.918379\ttraining's binary_logloss: 0.107843\tvalid_1's auc: 0.836042\tvalid_1's binary_logloss: 0.136657\n",
      "[54]\ttraining's auc: 0.918831\ttraining's binary_logloss: 0.107602\tvalid_1's auc: 0.835868\tvalid_1's binary_logloss: 0.136685\n",
      "[55]\ttraining's auc: 0.919586\ttraining's binary_logloss: 0.107402\tvalid_1's auc: 0.835994\tvalid_1's binary_logloss: 0.136655\n",
      "[56]\ttraining's auc: 0.920081\ttraining's binary_logloss: 0.107131\tvalid_1's auc: 0.835898\tvalid_1's binary_logloss: 0.136696\n",
      "[57]\ttraining's auc: 0.920822\ttraining's binary_logloss: 0.106908\tvalid_1's auc: 0.836243\tvalid_1's binary_logloss: 0.136641\n",
      "[58]\ttraining's auc: 0.922229\ttraining's binary_logloss: 0.106428\tvalid_1's auc: 0.835783\tvalid_1's binary_logloss: 0.136743\n",
      "[59]\ttraining's auc: 0.923338\ttraining's binary_logloss: 0.106011\tvalid_1's auc: 0.835888\tvalid_1's binary_logloss: 0.136724\n",
      "[60]\ttraining's auc: 0.923688\ttraining's binary_logloss: 0.105775\tvalid_1's auc: 0.835858\tvalid_1's binary_logloss: 0.136711\n",
      "[61]\ttraining's auc: 0.92411\ttraining's binary_logloss: 0.105503\tvalid_1's auc: 0.835951\tvalid_1's binary_logloss: 0.1367\n",
      "[62]\ttraining's auc: 0.924845\ttraining's binary_logloss: 0.105171\tvalid_1's auc: 0.83573\tvalid_1's binary_logloss: 0.136757\n",
      "[63]\ttraining's auc: 0.925526\ttraining's binary_logloss: 0.104879\tvalid_1's auc: 0.835525\tvalid_1's binary_logloss: 0.136823\n",
      "[64]\ttraining's auc: 0.925971\ttraining's binary_logloss: 0.104614\tvalid_1's auc: 0.835763\tvalid_1's binary_logloss: 0.136814\n",
      "[65]\ttraining's auc: 0.92698\ttraining's binary_logloss: 0.104347\tvalid_1's auc: 0.835984\tvalid_1's binary_logloss: 0.136801\n",
      "[66]\ttraining's auc: 0.927525\ttraining's binary_logloss: 0.104068\tvalid_1's auc: 0.83579\tvalid_1's binary_logloss: 0.136858\n",
      "[67]\ttraining's auc: 0.928562\ttraining's binary_logloss: 0.103732\tvalid_1's auc: 0.835872\tvalid_1's binary_logloss: 0.13685\n",
      "[68]\ttraining's auc: 0.928901\ttraining's binary_logloss: 0.103478\tvalid_1's auc: 0.83601\tvalid_1's binary_logloss: 0.136879\n",
      "[69]\ttraining's auc: 0.929666\ttraining's binary_logloss: 0.103154\tvalid_1's auc: 0.83586\tvalid_1's binary_logloss: 0.136892\n",
      "[70]\ttraining's auc: 0.93024\ttraining's binary_logloss: 0.102881\tvalid_1's auc: 0.835662\tvalid_1's binary_logloss: 0.136936\n",
      "[71]\ttraining's auc: 0.930595\ttraining's binary_logloss: 0.102626\tvalid_1's auc: 0.835792\tvalid_1's binary_logloss: 0.136922\n",
      "[72]\ttraining's auc: 0.930984\ttraining's binary_logloss: 0.1024\tvalid_1's auc: 0.83568\tvalid_1's binary_logloss: 0.136979\n",
      "[73]\ttraining's auc: 0.931308\ttraining's binary_logloss: 0.102231\tvalid_1's auc: 0.835546\tvalid_1's binary_logloss: 0.137007\n",
      "[74]\ttraining's auc: 0.931751\ttraining's binary_logloss: 0.101993\tvalid_1's auc: 0.83566\tvalid_1's binary_logloss: 0.136991\n",
      "[75]\ttraining's auc: 0.931933\ttraining's binary_logloss: 0.101847\tvalid_1's auc: 0.835681\tvalid_1's binary_logloss: 0.137008\n",
      "[76]\ttraining's auc: 0.932325\ttraining's binary_logloss: 0.101581\tvalid_1's auc: 0.835596\tvalid_1's binary_logloss: 0.13703\n",
      "[77]\ttraining's auc: 0.93252\ttraining's binary_logloss: 0.101418\tvalid_1's auc: 0.835315\tvalid_1's binary_logloss: 0.137124\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's auc: 0.914506\ttraining's binary_logloss: 0.10964\tvalid_1's auc: 0.836631\tvalid_1's binary_logloss: 0.136462\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-52-a98fe2285452>, line 31)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-52-a98fe2285452>\"\u001b[0;36m, line \u001b[0;32m31\u001b[0m\n\u001b[0;31m    return -1*np.mean(roc_auc_list)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def objective_func(search_space):\n",
    "    lgbm_clf = LGBMClassifier(n_estimators=100,\n",
    "                             num_leaves = int(search_space['num_leaves']),\n",
    "                             max_depth = int(search_space['max_depth']),\n",
    "                             min_child_samples = int(search_space['min_child_samples']),\n",
    "                             subsample = search_space['subsample'],\n",
    "                             learning_rate = search_space['learning_rate'])\n",
    "        \n",
    "        \n",
    "#3개 k-fold 방식으로 평가된 roc_auc 지표를 담는 list\n",
    "roc_auc_list = []\n",
    "\n",
    "#3개 k-fold 방식적용\n",
    "kf = KFold(n_splits= 3)\n",
    "\n",
    "\n",
    "# X traun을 다시 검증용 데이터로 분리\n",
    "for tr_index, val_index in kf.split(X_train):\n",
    "    X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n",
    "    X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "    \n",
    "    lgbm_clf.fit(X_tr, y_tr, early_stopping_rounds=30, eval_metric=\"auc\",\n",
    "    eval_set = [(X_tr, y_tr), (X_val, y_val)])\n",
    "    \n",
    "    score = roc_auc_score(y_val, lgbm_clf.predict_proba(X_val)[:,1])\n",
    "    roc_auc_list.append(score)\n",
    "    \n",
    "\n",
    "return -1*np.mean(roc_auc_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7c06aec7-6131-49b0-9485-0abf7632bffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9d6daf45-25f7-474f-a11c-b999d7e36df0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (<ipython-input-54-7cc7d6268c06>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-54-7cc7d6268c06>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    best = fmin (fn=objective_func, space_lgbm_search_space, algo=tpe.suggest,\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "best = fmin (fn=objective_func, space_lgbm_search_space, algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials, rstate=np,random.defalt_rng(seed=30))\n",
    "print('best:',best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3d7c62-3b98-4e5d-80ff-9697314881b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
