# Week 2 Study


지도학습=> 명시된 정답이 있는 데이터를 가지고 학습을 진행


# 1. 결정트리(Decision Tree)

- DS 트리구조를 기반으로 하는 알고리즘 많은 분류 기준을 가지고 있지만 레벨이 많아지고 트리가 깊어지면 예측 성능의 저하가 발생

- 균일한 데이터가 필요(결측치가 없어야 한다)

# 1.2 정보 이득( 균일도 측정 , Information Gain)

1. 정보 이득 지수 = 1 - 엔트로피 지수
> 엔트로피 = 데이터의 혼잡도 (값들의 종류가 많아짐 => 엔트로피 증가 , 같은값 많아짐 => 엔트로피 감소)
> 이 값을 기반으로 결정트리에서 속성을 분할한다.

2. 지니계수 : 0 ~ 1
> 소득의 불평등 정도를 나타내는 가장 대표적인 소득분배지표입니다. 지니계수는 0에서 1사이의 수치로 표시되는데 소득분배가 완전평등한 경우가 0, 완전불평등한 경우가 1입니다. 지니계수는 로렌츠곡선을 이용하여 계산할 수 있습니다.


# 1.3 앙상블 학습

## 1.3.1 보팅
> 여러가지 분류기를 통해 값을 예측하고 결과 값을 투표를 통해 결정 보팅은 배깅과 다르게 같은 데이터를 다른 모델을 통해 학습한다.

### 1.3.1.1 하드보팅
> 하드보팅은 다수결의 법칙과 비슷하게 여러가지 분류기로 값을 예측하고 다수의 결과값을 예측값으로 결정

### 1.3.1.2 소프트보팅
> 소프트 보팅은 결과값을 결정하는 결정 확률을 지정하고 그 값을 모두 더한고 평균값을 그 값을 결정하는 기준으로 지정한다.

## 1.3.2 배깅
> 배깅은 보팅과 값이 투표를 통해 결정하는 방식이지만 보팅과는 다르게 다른 데이터세트를 가지고 같은 모델을 통해서 값을 예측하는 방식이다.

## 1.3.3 부스팅
> 부스팅방식은 여러개의 분류기를 순차적으로 처리하고 이번 예측값이 실제 값과 틀리면 그 값을 에러 라고 판단하고 이후 분류기의 그 속성을 가중치를 주고 예측을 진행한다.
